{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HTTPX-CACHE httpx-cache is an implementation of the caching algorithms in httplib2 and CacheControl for use with httpx transport object. It is is heavily insipired by: https://github.com/ionrock/cachecontrol https://github.com/johtso/httpx-caching Installation Install with pip: $ pip install httpx-cache To use RedisCache , install with redis extra: $ pip install httpx-cache [ redis ] Requires Python 3.6+ and HTTPX 0.21+. Quickstart Usage with Client import httpx_cache with httpx_cache . Client () as client : response = client . get ( \"https://httpbin.org/get\" ) Usage with AsyncClient import httpx_cache async with httpx_cache . AsyncClient () as client : response = await client . get ( \"https://httpbin.org/get\" ) When using httpx-cache.Client / httpx_cache.AsyncClient , the interface and features (except caching) are exactly the same as httpx.Client / httpx.AsyncClient Read the User Guide for a complete walk-through. Supported Cache Types and Serializers Serializer DictCache FileCache RedisCache DictSerializer StringJsonSerializer BytesJsonSerializer MsgPackSerializer","title":"Introduction"},{"location":"#httpx-cache","text":"httpx-cache is an implementation of the caching algorithms in httplib2 and CacheControl for use with httpx transport object. It is is heavily insipired by: https://github.com/ionrock/cachecontrol https://github.com/johtso/httpx-caching","title":"HTTPX-CACHE"},{"location":"#installation","text":"Install with pip: $ pip install httpx-cache To use RedisCache , install with redis extra: $ pip install httpx-cache [ redis ] Requires Python 3.6+ and HTTPX 0.21+.","title":"Installation"},{"location":"#quickstart","text":"","title":"Quickstart"},{"location":"#usage-with-client","text":"import httpx_cache with httpx_cache . Client () as client : response = client . get ( \"https://httpbin.org/get\" )","title":"Usage with Client"},{"location":"#usage-with-asyncclient","text":"import httpx_cache async with httpx_cache . AsyncClient () as client : response = await client . get ( \"https://httpbin.org/get\" ) When using httpx-cache.Client / httpx_cache.AsyncClient , the interface and features (except caching) are exactly the same as httpx.Client / httpx.AsyncClient Read the User Guide for a complete walk-through.","title":"Usage with AsyncClient"},{"location":"#supported-cache-types-and-serializers","text":"Serializer DictCache FileCache RedisCache DictSerializer StringJsonSerializer BytesJsonSerializer MsgPackSerializer","title":"Supported Cache Types and Serializers"},{"location":"api/","text":"API documentation Client class httpx_cache. Client ( * , auth=None , params=None , headers=None , cookies=None , verify=True , cert=None , http1=True , http2=False , proxies=None , mounts=None , timeout=Timeout(timeout=5.0) , follow_redirects=False , limits=Limits(max_connections=100, max_keepalive_connections=20, keepalive_expiry=5.0) , max_redirects=20 , event_hooks=None , base_url='' , transport=None , app=None , trust_env=True , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) auth Authentication class used when none is passed at the request-level. See also Authentication . base_url Base URL to use when sending requests with relative URLs. build_request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , timeout= , extensions=None ) Build and return a request instance. The params , headers and cookies arguments are merged with any values set on the client. The url argument is merged with any base_url set on the client. See also: Request instances close ( self ) Close transport and proxies. cookies Cookie values to include when sending requests. delete ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a DELETE request. Parameters : See httpx.request . event_hooks get ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a GET request. Parameters : See httpx.request . head ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a HEAD request. Parameters : See httpx.request . headers HTTP headers to include when sending requests. is_closed Check if the client being closed options ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send an OPTIONS request. Parameters : See httpx.request . params Query parameters to include in the URL when sending requests. patch ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PATCH request. Parameters : See httpx.request . post ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a POST request. Parameters : See httpx.request . put ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PUT request. Parameters : See httpx.request . request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Build and send a request. Equivalent to: request = client . build_request ( ... ) response = client . send ( request , ... ) See Client.build_request() , Client.send() and Merging of configuration for how the various parameters are merged with client-level configuration. send ( self , request , * , stream=False , auth= , follow_redirects= ) Send a request. The request is sent as-is, unmodified. Typically you'll want to build one with Client.build_request() so that any client-level configuration is merged into the request, but passing an explicit httpx.Request() is supported as well. See also: Request instances stream ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Alternative to httpx.request() that streams the response body instead of loading it into memory at once. Parameters : See httpx.request . See also: Streaming Responses timeout trust_env class httpx_cache. AsyncClient ( * , auth=None , params=None , headers=None , cookies=None , verify=True , cert=None , http1=True , http2=False , proxies=None , mounts=None , timeout=Timeout(timeout=5.0) , follow_redirects=False , limits=Limits(max_connections=100, max_keepalive_connections=20, keepalive_expiry=5.0) , max_redirects=20 , event_hooks=None , base_url='' , transport=None , app=None , trust_env=True , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) async aclose ( self ) Close transport and proxies. auth Authentication class used when none is passed at the request-level. See also Authentication . base_url Base URL to use when sending requests with relative URLs. build_request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , timeout= , extensions=None ) Build and return a request instance. The params , headers and cookies arguments are merged with any values set on the client. The url argument is merged with any base_url set on the client. See also: Request instances cookies Cookie values to include when sending requests. async delete ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a DELETE request. Parameters : See httpx.request . event_hooks async get ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a GET request. Parameters : See httpx.request . async head ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a HEAD request. Parameters : See httpx.request . headers HTTP headers to include when sending requests. is_closed Check if the client being closed async options ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send an OPTIONS request. Parameters : See httpx.request . params Query parameters to include in the URL when sending requests. async patch ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PATCH request. Parameters : See httpx.request . async post ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a POST request. Parameters : See httpx.request . async put ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PUT request. Parameters : See httpx.request . async request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Build and send a request. Equivalent to: request = client . build_request ( ... ) response = await client . send ( request , ... ) See AsyncClient.build_request() , AsyncClient.send() and Merging of configuration for how the various parameters are merged with client-level configuration. async send ( self , request , * , stream=False , auth= , follow_redirects= ) Send a request. The request is sent as-is, unmodified. Typically you'll want to build one with AsyncClient.build_request() so that any client-level configuration is merged into the request, but passing an explicit httpx.Request() is supported as well. See also: Request instances stream ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Alternative to httpx.request() that streams the response body instead of loading it into memory at once. Parameters : See httpx.request . See also: Streaming Responses timeout trust_env Transport class httpx_cache. CacheControlTransport ( * , transport=None , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) CacheControl transport for httpx_cache. Args: transport (optional): an existing httpx transport, if no transport is given, defaults to an httpx.HTTPTransport with default args. cache (optional): cache to use with this transport, defaults to httpx_cache.DictCache cacheable_methods: methods that are allowed to be cached, defaults to ['GET'] cacheable_status_codes: status codes that are allowed to be cached, defaults to: (200, 203, 300, 301, 308) close ( self ) handle_request ( self , request ) class httpx_cache. AsyncCacheControlTransport ( * , transport=None , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) Async CacheControl transport for httpx_cache. Args: transport (optional): an existing httpx async-transport, if no transport is given, defaults to an httpx.AsyncHTTPTransport with default args. cache (optional): cache to use with this transport, defaults to httpx_cache.DictCache cacheable_methods: methods that are allowed to be cached, defaults to ['GET'] cacheable_status_codes: status codes that are allowed to be cached, defaults to: (200, 203, 300, 301, 308) async aclose ( self ) async handle_async_request ( self , request ) CacheControl class httpx_cache. CacheControl ( * , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) Cache controller for httpx-cache. Uses 'cache-contol' header direcrives for using/skipping cache. If no cache-control directive is set, the cache is used by default (except if there is an expires header in the response.) is_request_cacheable ( self , request ) Checks if an httpx request has the necessary requirement to support caching. A request is cacheable if: - url is absolute - method is defined as cacheable (by default only GET methods are cached) - request has no 'no-cache' cache-control header directive - request has no 'max-age=0' cache-control header directive Args: request: httpx.Request Returns: True if request cacheable else False is_response_cacheable ( self , * , request , response ) Check if an httpx response is cacheable. A respons is cacheable if: - response status_code is cacheable - request method is cacheable - One of: - always_cache is True OR: - Response has no 'no-store' cache-control header - Request has no 'no-store' cache-control header Args: request: httpx.Request response: httpx.Response Returns: wether response is cacheable or not. is_response_fresh ( self , * , request , response ) Checks wether a cached response is fresh or not. Args: request: httpx.Request response: httpx.Response Returns: True if request is fresh else False Cache class httpx_cache. DictCache ( data=None , serializer=None ) Simple in-memory dict cache. Uses a lock/async_lock to make sure each get/set/delete operation is safe. Args: data: Optional initial data for the cache {str: Any}, default to {} serializer: Optional serializer for the data to cache, defaults to: httpx_cache.MsgPackSerializer async aclose ( self ) (Async) Close cache. async adelete ( self , request ) async aget ( self , request ) async aset ( self , * , request , response , content=None ) async_lock close ( self ) Close cache. delete ( self , request ) get ( self , request ) lock set ( self , * , request , response , content=None ) class httpx_cache. FileCache ( cache_dir=None , serializer=None ) File cache that stores cached responses in files on disk. Uses a lock/async_lock to make sure each get/set/delete operation is safe. Args: cache_dir: Optional custom cache_dir where to store cache files, defaults to ~/.cache/httpx-cache serializer: Optional serializer for the data to cache, defaults to: httpx_cache.MsgPackSerializer async aclose ( self ) (Async) Close cache. async adelete ( self , request ) async aget ( self , request ) async aset ( self , * , request , response , content=None ) async_lock close ( self ) Close cache. delete ( self , request ) get ( self , request ) lock A reader/writer lock. This lock allows for simultaneous readers to exist but only one writer to exist for use-cases where it is useful to have such types of locks. Currently a reader can not escalate its read lock to a write lock and a writer can not acquire a read lock while it is waiting on the write lock. In the future these restrictions may be relaxed. This can be eventually removed if http://bugs.python.org/issue8800 ever gets accepted into the python standard threading library... set ( self , * , request , response , content=None ) class httpx_cache.cache.redis. RedisCache ( serializer=None , namespace='httpx_cache' , redis_url='' , redis=None , aredis=None , default_ttl=None ) Redis cache that stores cached responses in Redis. Uses a lock/async_lock to make sure each get/set/delete operation is safe. You can either provide an instance of 'Redis'/'AsyncRedis' or a redis url to have RedisCache create the connection for you. Args: serializer: Optional serializer for the data to cache, defaults to: httpx_cache.MsgPackSerializer namespace: Optional namespace for the cache keys, defaults to \"httpx_cache\" redis_url: Optional redis url, defaults to empty string redis: Optional redis instance, defaults to None aredis: Optional async redis instance, defaults to None default_ttl: Optional default ttl for cached responses, defaults to None async aclose ( self ) async adelete ( self , request ) async aget ( self , request ) async aset ( self , * , request , response , content=None ) async_lock close ( self ) delete ( self , request ) get ( self , request ) lock A reader/writer lock. This lock allows for simultaneous readers to exist but only one writer to exist for use-cases where it is useful to have such types of locks. Currently a reader can not escalate its read lock to a write lock and a writer can not acquire a read lock while it is waiting on the write lock. In the future these restrictions may be relaxed. This can be eventually removed if http://bugs.python.org/issue8800 ever gets accepted into the python standard threading library... set ( self , * , request , response , content=None ) !!! Note FileCache and RedisCache only supports httpx_cache.MsgPackSerializer and httpx_cache.BytesJsonSerializer serializers. Serializer class httpx_cache. DictSerializer ( ) Dumps and loads and httpx.Response into/from a python dict. The dict contains the state of the response, with all necessary info to recreate it. dumps ( self , * , response , content=None ) Converts and httpx.Response into a dict with it's state. The goal is that this state we are able later to reconstruct the same response later on. In case the response does not yet have a '_content' property, content should be provided in the optional 'content' kwarg (usually using a callback) Args: response: httpx.Response content (bytes, optional): Defaults to None, should be provided in case response that not have yet content. Raises: httpx.ResponseNotRead: if response does not have content and no content is provided Returns: Dict[str, Any] loads ( self , * , cached , request=None ) Convert a dict (contains response state) to an httpx.Response instance. Args: state: Dict of the state of teh response to create request (httpx.Request, optional): Defaults to None, request to optionally attach to the response Returns: httpx.Response class httpx_cache. StringJsonSerializer ( ) Serialize an httpx.Response using python Json Encoder. Serialized data is returned as a JSON string. The serialized data contains the state of the response, with all necessary info to recreate it. NB: bytes are automatically parsed as strings when using this serializer, when recreating response the loader is smart enough to know which key/value need to be bytes and not strings (like: _content/stream) dumps ( self , * , response , content=None ) Dump an httpx.Response to json string. loads ( self , * , cached , request=None ) Load an httpx.Response from a json string class httpx_cache. BytesJsonSerializer ( ) Same as httpx_cache.StringJsonSerializer, but converts the dumped strings into bytes (encoded/decode with utf-8). dumps ( self , * , response , content=None ) Dump an httpx.Response to an utf-8 encoded bytes string. loads ( self , * , cached , request=None ) Load an httpx.Response to an utf-8 encoded bytes string. class httpx_cache. MsgPackSerializer ( ) Serialize an httpx.Response using msgpack. Serialized data is returned as a bytes. The serialized data contains the state of the response, with all necessary info to recreate it. dumps ( self , * , response , content=None ) Dump an httpx.Response to msgapck bytes. loads ( self , * , cached , request=None ) Load an httpx.Response from a msgapck bytes.","title":"Developer Interface"},{"location":"api/#api-documentation","text":"","title":"API documentation"},{"location":"api/#client","text":"class httpx_cache. Client ( * , auth=None , params=None , headers=None , cookies=None , verify=True , cert=None , http1=True , http2=False , proxies=None , mounts=None , timeout=Timeout(timeout=5.0) , follow_redirects=False , limits=Limits(max_connections=100, max_keepalive_connections=20, keepalive_expiry=5.0) , max_redirects=20 , event_hooks=None , base_url='' , transport=None , app=None , trust_env=True , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) auth Authentication class used when none is passed at the request-level. See also Authentication . base_url Base URL to use when sending requests with relative URLs. build_request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , timeout= , extensions=None ) Build and return a request instance. The params , headers and cookies arguments are merged with any values set on the client. The url argument is merged with any base_url set on the client. See also: Request instances close ( self ) Close transport and proxies. cookies Cookie values to include when sending requests. delete ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a DELETE request. Parameters : See httpx.request . event_hooks get ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a GET request. Parameters : See httpx.request . head ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a HEAD request. Parameters : See httpx.request . headers HTTP headers to include when sending requests. is_closed Check if the client being closed options ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send an OPTIONS request. Parameters : See httpx.request . params Query parameters to include in the URL when sending requests. patch ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PATCH request. Parameters : See httpx.request . post ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a POST request. Parameters : See httpx.request . put ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PUT request. Parameters : See httpx.request . request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Build and send a request. Equivalent to: request = client . build_request ( ... ) response = client . send ( request , ... ) See Client.build_request() , Client.send() and Merging of configuration for how the various parameters are merged with client-level configuration. send ( self , request , * , stream=False , auth= , follow_redirects= ) Send a request. The request is sent as-is, unmodified. Typically you'll want to build one with Client.build_request() so that any client-level configuration is merged into the request, but passing an explicit httpx.Request() is supported as well. See also: Request instances stream ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Alternative to httpx.request() that streams the response body instead of loading it into memory at once. Parameters : See httpx.request . See also: Streaming Responses timeout trust_env class httpx_cache. AsyncClient ( * , auth=None , params=None , headers=None , cookies=None , verify=True , cert=None , http1=True , http2=False , proxies=None , mounts=None , timeout=Timeout(timeout=5.0) , follow_redirects=False , limits=Limits(max_connections=100, max_keepalive_connections=20, keepalive_expiry=5.0) , max_redirects=20 , event_hooks=None , base_url='' , transport=None , app=None , trust_env=True , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) async aclose ( self ) Close transport and proxies. auth Authentication class used when none is passed at the request-level. See also Authentication . base_url Base URL to use when sending requests with relative URLs. build_request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , timeout= , extensions=None ) Build and return a request instance. The params , headers and cookies arguments are merged with any values set on the client. The url argument is merged with any base_url set on the client. See also: Request instances cookies Cookie values to include when sending requests. async delete ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a DELETE request. Parameters : See httpx.request . event_hooks async get ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a GET request. Parameters : See httpx.request . async head ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a HEAD request. Parameters : See httpx.request . headers HTTP headers to include when sending requests. is_closed Check if the client being closed async options ( self , url , * , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send an OPTIONS request. Parameters : See httpx.request . params Query parameters to include in the URL when sending requests. async patch ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PATCH request. Parameters : See httpx.request . async post ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a POST request. Parameters : See httpx.request . async put ( self , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Send a PUT request. Parameters : See httpx.request . async request ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Build and send a request. Equivalent to: request = client . build_request ( ... ) response = await client . send ( request , ... ) See AsyncClient.build_request() , AsyncClient.send() and Merging of configuration for how the various parameters are merged with client-level configuration. async send ( self , request , * , stream=False , auth= , follow_redirects= ) Send a request. The request is sent as-is, unmodified. Typically you'll want to build one with AsyncClient.build_request() so that any client-level configuration is merged into the request, but passing an explicit httpx.Request() is supported as well. See also: Request instances stream ( self , method , url , * , content=None , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth= , follow_redirects= , timeout= , extensions=None ) Alternative to httpx.request() that streams the response body instead of loading it into memory at once. Parameters : See httpx.request . See also: Streaming Responses timeout trust_env","title":"Client"},{"location":"api/#transport","text":"class httpx_cache. CacheControlTransport ( * , transport=None , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) CacheControl transport for httpx_cache. Args: transport (optional): an existing httpx transport, if no transport is given, defaults to an httpx.HTTPTransport with default args. cache (optional): cache to use with this transport, defaults to httpx_cache.DictCache cacheable_methods: methods that are allowed to be cached, defaults to ['GET'] cacheable_status_codes: status codes that are allowed to be cached, defaults to: (200, 203, 300, 301, 308) close ( self ) handle_request ( self , request ) class httpx_cache. AsyncCacheControlTransport ( * , transport=None , cache=None , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) Async CacheControl transport for httpx_cache. Args: transport (optional): an existing httpx async-transport, if no transport is given, defaults to an httpx.AsyncHTTPTransport with default args. cache (optional): cache to use with this transport, defaults to httpx_cache.DictCache cacheable_methods: methods that are allowed to be cached, defaults to ['GET'] cacheable_status_codes: status codes that are allowed to be cached, defaults to: (200, 203, 300, 301, 308) async aclose ( self ) async handle_async_request ( self , request )","title":"Transport"},{"location":"api/#cachecontrol","text":"class httpx_cache. CacheControl ( * , cacheable_methods=('GET',) , cacheable_status_codes=(200, 203, 300, 301, 308) , always_cache=False ) Cache controller for httpx-cache. Uses 'cache-contol' header direcrives for using/skipping cache. If no cache-control directive is set, the cache is used by default (except if there is an expires header in the response.) is_request_cacheable ( self , request ) Checks if an httpx request has the necessary requirement to support caching. A request is cacheable if: - url is absolute - method is defined as cacheable (by default only GET methods are cached) - request has no 'no-cache' cache-control header directive - request has no 'max-age=0' cache-control header directive Args: request: httpx.Request Returns: True if request cacheable else False is_response_cacheable ( self , * , request , response ) Check if an httpx response is cacheable. A respons is cacheable if: - response status_code is cacheable - request method is cacheable - One of: - always_cache is True OR: - Response has no 'no-store' cache-control header - Request has no 'no-store' cache-control header Args: request: httpx.Request response: httpx.Response Returns: wether response is cacheable or not. is_response_fresh ( self , * , request , response ) Checks wether a cached response is fresh or not. Args: request: httpx.Request response: httpx.Response Returns: True if request is fresh else False","title":"CacheControl"},{"location":"api/#cache","text":"class httpx_cache. DictCache ( data=None , serializer=None ) Simple in-memory dict cache. Uses a lock/async_lock to make sure each get/set/delete operation is safe. Args: data: Optional initial data for the cache {str: Any}, default to {} serializer: Optional serializer for the data to cache, defaults to: httpx_cache.MsgPackSerializer async aclose ( self ) (Async) Close cache. async adelete ( self , request ) async aget ( self , request ) async aset ( self , * , request , response , content=None ) async_lock close ( self ) Close cache. delete ( self , request ) get ( self , request ) lock set ( self , * , request , response , content=None ) class httpx_cache. FileCache ( cache_dir=None , serializer=None ) File cache that stores cached responses in files on disk. Uses a lock/async_lock to make sure each get/set/delete operation is safe. Args: cache_dir: Optional custom cache_dir where to store cache files, defaults to ~/.cache/httpx-cache serializer: Optional serializer for the data to cache, defaults to: httpx_cache.MsgPackSerializer async aclose ( self ) (Async) Close cache. async adelete ( self , request ) async aget ( self , request ) async aset ( self , * , request , response , content=None ) async_lock close ( self ) Close cache. delete ( self , request ) get ( self , request ) lock A reader/writer lock. This lock allows for simultaneous readers to exist but only one writer to exist for use-cases where it is useful to have such types of locks. Currently a reader can not escalate its read lock to a write lock and a writer can not acquire a read lock while it is waiting on the write lock. In the future these restrictions may be relaxed. This can be eventually removed if http://bugs.python.org/issue8800 ever gets accepted into the python standard threading library... set ( self , * , request , response , content=None ) class httpx_cache.cache.redis. RedisCache ( serializer=None , namespace='httpx_cache' , redis_url='' , redis=None , aredis=None , default_ttl=None ) Redis cache that stores cached responses in Redis. Uses a lock/async_lock to make sure each get/set/delete operation is safe. You can either provide an instance of 'Redis'/'AsyncRedis' or a redis url to have RedisCache create the connection for you. Args: serializer: Optional serializer for the data to cache, defaults to: httpx_cache.MsgPackSerializer namespace: Optional namespace for the cache keys, defaults to \"httpx_cache\" redis_url: Optional redis url, defaults to empty string redis: Optional redis instance, defaults to None aredis: Optional async redis instance, defaults to None default_ttl: Optional default ttl for cached responses, defaults to None async aclose ( self ) async adelete ( self , request ) async aget ( self , request ) async aset ( self , * , request , response , content=None ) async_lock close ( self ) delete ( self , request ) get ( self , request ) lock A reader/writer lock. This lock allows for simultaneous readers to exist but only one writer to exist for use-cases where it is useful to have such types of locks. Currently a reader can not escalate its read lock to a write lock and a writer can not acquire a read lock while it is waiting on the write lock. In the future these restrictions may be relaxed. This can be eventually removed if http://bugs.python.org/issue8800 ever gets accepted into the python standard threading library... set ( self , * , request , response , content=None ) !!! Note FileCache and RedisCache only supports httpx_cache.MsgPackSerializer and httpx_cache.BytesJsonSerializer serializers.","title":"Cache"},{"location":"api/#serializer","text":"class httpx_cache. DictSerializer ( ) Dumps and loads and httpx.Response into/from a python dict. The dict contains the state of the response, with all necessary info to recreate it. dumps ( self , * , response , content=None ) Converts and httpx.Response into a dict with it's state. The goal is that this state we are able later to reconstruct the same response later on. In case the response does not yet have a '_content' property, content should be provided in the optional 'content' kwarg (usually using a callback) Args: response: httpx.Response content (bytes, optional): Defaults to None, should be provided in case response that not have yet content. Raises: httpx.ResponseNotRead: if response does not have content and no content is provided Returns: Dict[str, Any] loads ( self , * , cached , request=None ) Convert a dict (contains response state) to an httpx.Response instance. Args: state: Dict of the state of teh response to create request (httpx.Request, optional): Defaults to None, request to optionally attach to the response Returns: httpx.Response class httpx_cache. StringJsonSerializer ( ) Serialize an httpx.Response using python Json Encoder. Serialized data is returned as a JSON string. The serialized data contains the state of the response, with all necessary info to recreate it. NB: bytes are automatically parsed as strings when using this serializer, when recreating response the loader is smart enough to know which key/value need to be bytes and not strings (like: _content/stream) dumps ( self , * , response , content=None ) Dump an httpx.Response to json string. loads ( self , * , cached , request=None ) Load an httpx.Response from a json string class httpx_cache. BytesJsonSerializer ( ) Same as httpx_cache.StringJsonSerializer, but converts the dumped strings into bytes (encoded/decode with utf-8). dumps ( self , * , response , content=None ) Dump an httpx.Response to an utf-8 encoded bytes string. loads ( self , * , cached , request=None ) Load an httpx.Response to an utf-8 encoded bytes string. class httpx_cache. MsgPackSerializer ( ) Serialize an httpx.Response using msgpack. Serialized data is returned as a bytes. The serialized data contains the state of the response, with all necessary info to recreate it. dumps ( self , * , response , content=None ) Dump an httpx.Response to msgapck bytes. loads ( self , * , cached , request=None ) Load an httpx.Response from a msgapck bytes.","title":"Serializer"},{"location":"cache_control/","text":"Cache Control By defaults httpx-cache caches every response that: has a cacheable status_code in (200, 203, 300, 301, 308) (can be modified) corresponding request has a cacheable method in ('GET',) (can be modified) corresponding request has an absolute url Enabling/Disabling cache can also be configured at the operation level using cache-control headers directives ( https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control ) Disable Checking Cache Disabling cache on a particular request can be achieved by setting either the cache-control: no-cache or cache-control: max-age=0 headers. The no-cache request directive asks caches to validate the response with the origin server before reuse. no-cache allows clients to request the most up-to-date response even if the cache has a fresh response. Browsers usually add no-cache to requests when users are force reloading a page. import httpx_cache with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" ) # will be cached response2 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-cache\" }) # will NOT get it from cache, but it will make a new request that then will be re-cached again (refreched in the cache) Disable Storing in Cache Sometimes we want to make a request but not store a response in cache, so that we always get the freshest response. This can be achieved with cache-control: no-store header. The no-store response/request directive indicates that any caches of any kind (private or shared) should not store this response. NOTE : a no-store cache-control directive can also be set on the response headers by the server, in that case it will not be cached too. import httpx_cache with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-cache\" }) # will not be stored in cache response2 = client . get ( \"https://httpbin.org/get\" ) # cache is empty since previous request was not stored, will make a new request. Always Cache In the case where we want to ignore the no-store directive in the response headers, we can set the parameter always_cache=True . This parameter can be set on the client or on the transport . Note: Event when always_cache=True is set, the cache controller will still does the basic checks to make sure the response is cacheable, namely: status_code is cacheable, request method is cacheable, and request url is absolute. Usage with client : import httpx_cache with httpx_cache . Client ( always_cache = True ) as client : response1 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-store\" }) # will be stored in cache response2 = client . get ( \"https://httpbin.org/get\" ) # cache is not empty since previous request was stored, will NOT make a new request. Usage with transport : import httpx_cache with httpx_cache . Client ( transport = httpx_cache . CachedTransport ( always_cache = True )) as client : response1 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-store\" }) # will be stored in cache response2 = client . get ( \"https://httpbin.org/get\" ) # cache is not empty since previous request was stored, will NOT make a new request. Cache Expiration Max-Age Directive Cache expiration can be controlled with the request (or response) max-age direvtive (directives found in a request take precedence over those in a response.) The max-age=N request or response directive indicates that the client allows a stored response that is generated on the origin server within N seconds. Ff the response with cache-control: max-age=604800 was stored in caches 3 hours ago, httpx-cache couldn't reuse that response. import httpx_cache import time with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" ) # store in cache at time T time . sleep ( 10 ) # sleep for 10s (T+10) response2 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"max-age=5\" }) # response in cache has expried since T+5 < T+10 # cached response will be deleted Expires Header In addition to the max-age directive, we can achieve the same effect with the expires header. Use your own CacheController To use your own cache controller with custom logic for when to cache a response, you can directly subclass httpx_cache.CacheController and httpx_cache.CacheControlTransport (or httpx_cache.AsyncCacheControlTransport ): import httpx import httpx_cache class MyCacheController ( httpx_cache . CacheController ): def is_response_cacheable ( self , response : httpx . Response ) -> bool : # always cache responses return True class MyCacheControlTransport ( httpx_cache . CacheControlTransport ): def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) self . cache_controller = MyCacheController ()","title":"Cache Control"},{"location":"cache_control/#cache-control","text":"By defaults httpx-cache caches every response that: has a cacheable status_code in (200, 203, 300, 301, 308) (can be modified) corresponding request has a cacheable method in ('GET',) (can be modified) corresponding request has an absolute url Enabling/Disabling cache can also be configured at the operation level using cache-control headers directives ( https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control )","title":"Cache Control"},{"location":"cache_control/#disable-checking-cache","text":"Disabling cache on a particular request can be achieved by setting either the cache-control: no-cache or cache-control: max-age=0 headers. The no-cache request directive asks caches to validate the response with the origin server before reuse. no-cache allows clients to request the most up-to-date response even if the cache has a fresh response. Browsers usually add no-cache to requests when users are force reloading a page. import httpx_cache with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" ) # will be cached response2 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-cache\" }) # will NOT get it from cache, but it will make a new request that then will be re-cached again (refreched in the cache)","title":"Disable Checking Cache"},{"location":"cache_control/#disable-storing-in-cache","text":"Sometimes we want to make a request but not store a response in cache, so that we always get the freshest response. This can be achieved with cache-control: no-store header. The no-store response/request directive indicates that any caches of any kind (private or shared) should not store this response. NOTE : a no-store cache-control directive can also be set on the response headers by the server, in that case it will not be cached too. import httpx_cache with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-cache\" }) # will not be stored in cache response2 = client . get ( \"https://httpbin.org/get\" ) # cache is empty since previous request was not stored, will make a new request.","title":"Disable Storing in Cache"},{"location":"cache_control/#always-cache","text":"In the case where we want to ignore the no-store directive in the response headers, we can set the parameter always_cache=True . This parameter can be set on the client or on the transport . Note: Event when always_cache=True is set, the cache controller will still does the basic checks to make sure the response is cacheable, namely: status_code is cacheable, request method is cacheable, and request url is absolute. Usage with client : import httpx_cache with httpx_cache . Client ( always_cache = True ) as client : response1 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-store\" }) # will be stored in cache response2 = client . get ( \"https://httpbin.org/get\" ) # cache is not empty since previous request was stored, will NOT make a new request. Usage with transport : import httpx_cache with httpx_cache . Client ( transport = httpx_cache . CachedTransport ( always_cache = True )) as client : response1 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"no-store\" }) # will be stored in cache response2 = client . get ( \"https://httpbin.org/get\" ) # cache is not empty since previous request was stored, will NOT make a new request.","title":"Always Cache"},{"location":"cache_control/#cache-expiration","text":"","title":"Cache Expiration"},{"location":"cache_control/#max-age-directive","text":"Cache expiration can be controlled with the request (or response) max-age direvtive (directives found in a request take precedence over those in a response.) The max-age=N request or response directive indicates that the client allows a stored response that is generated on the origin server within N seconds. Ff the response with cache-control: max-age=604800 was stored in caches 3 hours ago, httpx-cache couldn't reuse that response. import httpx_cache import time with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" ) # store in cache at time T time . sleep ( 10 ) # sleep for 10s (T+10) response2 = client . get ( \"https://httpbin.org/get\" , headers = { \"cache-control\" : \"max-age=5\" }) # response in cache has expried since T+5 < T+10 # cached response will be deleted","title":"Max-Age Directive"},{"location":"cache_control/#expires-header","text":"In addition to the max-age directive, we can achieve the same effect with the expires header.","title":"Expires Header"},{"location":"cache_control/#use-your-own-cachecontroller","text":"To use your own cache controller with custom logic for when to cache a response, you can directly subclass httpx_cache.CacheController and httpx_cache.CacheControlTransport (or httpx_cache.AsyncCacheControlTransport ): import httpx import httpx_cache class MyCacheController ( httpx_cache . CacheController ): def is_response_cacheable ( self , response : httpx . Response ) -> bool : # always cache responses return True class MyCacheControlTransport ( httpx_cache . CacheControlTransport ): def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) self . cache_controller = MyCacheController ()","title":"Use your own CacheController"},{"location":"guide/","text":"User Guide httpx-cache provides: A sync/async httpx compatible caching client and/or transport. Support for an in memeory dict cache and a file cache. Support for different serializers: dict, str, bytes, msgpack Client httpx recommends usig a client instance of anything more that experimentation, one-off scripts, or prototypes. Caching is one such advanced use cases, that's why httpx-cache provides it's own Custom client that has exactly the same features as the original httpx.Client (inherits from the httpx.Client class), but wraps the default (or custom) transport in an httpx_cache.CacheControlTransport . Usage with Default Values Excluding the caching algorithms, httpx_cache.Client (or AsyncClient ) behaves similary to httpx.Client (or AsyncClient ). For caching, httpx_cache.Client adds 3 new key-args to the table: cache : An optional value for which cache type to use, defaults to an in-memory dict cache if not provided. cacheable_methods : tuple of str http methods that support caching (if a request does not use one of these methods, it's corresponding response will not be cached), defaults to ('GET',) cacheable_status_codes : tuple of int http status codes that supports caching (if response does not have one of these status codes, it will not be cached), defaults to: (200, 203, 300, 301, 308) always_cache : bool, if True, all valid responses will be cached, regardless of the no-store directive set in either the request or response, defaults to False. Note: When using the httpx_cache client or transport, a new property will be added to the response to specify whether it comes from cache or not: response.from_cache: bool Example usage: import httpx_cache with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" ) # will be cached response2 = client . get ( \"https://httpbin.org/get\" ) # will get it from cache assert response1 . from_cache is False assert response2 . from_cache is True AsyncClient Same as httpx.AsyncClient , httpx_cache also provides an httpx_cache.AsyncClient that supports samencaching args as httpx_cache.Client . import httpx_cache async with httpx_cache . AsyncClient () as client : response1 = await client . get ( \"https://httpbin.org/get\" ) # will be cached response2 = await client . get ( \"https://httpbin.org/get\" ) # will get it from cache assert response1 . from_cache is False assert response2 . from_cache is True Response Stream When using a streaming response, the response will not be cached until the stream is fully consumed. The reason being that to cache a response we need it to have a content property and this content is set only when the user has fully consumed the stream. (httpx_cache handles this automatically with a callback, it should have no effect on the user usual routines when using a stream.) import logging import tempfile import rich.progress from rich.logging import RichHandler import httpx_cache logging . basicConfig ( level = \"DEBUG\" , format = \" %(message)s \" , datefmt = \"[ %X ]\" , handlers = [ RichHandler ()] ) logger = logging . getLogger ( \"httpx_cache.example\" ) with tempfile . NamedTemporaryFile () as download_file : url = \"https://speed.hetzner.de/100MB.bin\" with httpx_cache . Client () as client : logger . info ( f \"Running ' { url } ' download for the first time ...\" ) with client . stream ( \"GET\" , url ) as response : total = int ( response . headers [ \"Content-Length\" ]) logger . info ( \"A streaming response is cached only after the stream is consumed.\" ) with rich . progress . Progress ( \"[progress.percentage] {task.percentage:>3.0f} %\" , rich . progress . BarColumn ( bar_width = None ), rich . progress . DownloadColumn (), rich . progress . TransferSpeedColumn (), rich . progress . TimeElapsedColumn (), ) as progress : download_task = progress . add_task ( \"Download\" , total = total ) for chunk in response . iter_bytes (): download_file . write ( chunk ) progress . update ( download_task , completed = response . num_bytes_downloaded ) logger . info ( f \"Running same ' { url } ' download for the second time ...\" ) logger . info ( \"The response is cached so it should take 0 seconds to iter over \" \"the bin again !\" ) with client . stream ( \"GET\" , url ) as response2 : total = int ( response2 . headers [ \"Content-Length\" ]) with rich . progress . Progress ( \"[progress.percentage] {task.percentage:>3.0f} %\" , rich . progress . BarColumn ( bar_width = None ), rich . progress . DownloadColumn (), rich . progress . TransferSpeedColumn (), rich . progress . TimeElapsedColumn (), ) as progress : download_task = progress . add_task ( \"Download\" , total = total ) for chunk in response2 . iter_bytes (): download_file . write ( chunk ) progress . update ( download_task , completed = response2 . num_bytes_downloaded ) (This script is complete, it should run \"as is\") Transport If you prefer to use the original httpx Client, httpx-cache also provides a transport that can be used dircetly with it: The custom caching transport is created following the guilelines here . The (Async-)CacheControlTransport also accepts the 3 key-args: cache : An optional value for which cache type to use, defaults to an in-memory dict cache if not provided. cacheable_methods : tuple of str http methods that support caching (if a request does not use one of these methods, it's corresponding response will not be cached), defaults to ('GET',) cacheable_status_codes : tuple of int http status codes that supports caching (if response does not have one of these status codes, it will not be cached), defaults to: (200, 203, 300, 301, 308) Note: When using the httpx_cache client or transport, a new property will be added to the response to specify whether it comes from cache or not: response.from_cache: bool import httpx import httpx_cache with httpx . Client ( transport = httpx_cache . CacheControlTransport ()) as client : response = client . get ( \"https://httpbin.org/get\" ) # async with httpx.AsyncClient(transport=httpx_cache.AsyncCacheControlTransport()) as client: # response = await client.get(\"https://httpbin.org/get\") Cache Types DictCache (default) In-memory dict cache: import httpx import httpx_cache with httpx_cache . Client ( cache = httpx_cache . DictCache ()) as client : response = client . get ( \"https://httpbin.org/get\" ) FileCache import httpx_cache with httpx_cache . Client ( cache = httpx_cache . FileCache ()) as client : response = client . get ( \"https://httpbin.org/get\" ) By default the cached files will be saved in $HOME/.cache/httpx-cache folder. It can be customized using the argument: cache_dir : import httpx_cache with httpx_cache . Client ( cache = httpx_cache . FileCache ( cache_dir = \"./my-custom-dir\" )) as client : response = client . get ( \"https://httpbin.org/get\" ) fsspec/universal_pathlib integration Filecache also works out of the box with fsspec/universal_pathlib so that you can use any filesystem supported by fsspec as a cachedir. Please check the fsspec/universal_pathlib docs for the list of supported filesystems (and schemes) Example with an s3 filesystem: (don't forget to also install the s3fs package to use this backend: pip install universal_pathlib s3fs ) import httpx_cache from upath import UPath cache_dir = UPath ( \"s3://my-bucket/httpx-cache\" ) cache = httpx_cache . FileCache ( cache_dir = cache_dir ) with httpx_cache . Client ( cache = cache ) as client : response = client . get ( \"https://httpbin.org/get\" ) # OR async client # async with httpx_cache.AsyncClient(cache=cache) as client: # response = await client.get(\"https://httpbin.org/get\") # should contain one file, with the cached response print ([ f for f in cache_dir . iterdir ()]) RedisCache You need to install redis package to use this cache type, or install httpx-cache[redis] to install it automatically. import httpx_cache from httpx_cache.cache.redis import RedisCache with httpx_cache . Client ( cache = RedisCache ( redis_url = \"redis://localhost:6379/0\" )) as client : response = client . get ( \"https://httpbin.org/get\" ) By default all cached responses are saved under the namespace htppx_cache . Optionally a TTL can be provided so that the cached responses expire after the given time (as a python timedelta). It can also accepts direct instances of redis.Redis or redis.StrictRedis clients. import httpx_cache from redis import Redis from httpx_cache.cache.redis import RedisCache redis_client = Redis ( host = \"localhost\" , port = 6379 , db = 0 ) cache = RedisCache ( redis = redis_client , namespace = \"my-custom-namespace\" , default_ttl = timedelta ( hours = 1 )) with httpx_cache . Client ( cache = cache ) as client : response = client . get ( \"https://httpbin.org/get\" ) Serializer Types Before caching an httpx.Response it needs to be serialized to a cacheable format supported by the used cache type (Dict/File). Serializer DictCache FileCache RedisCache DictSerializer StringJsonSerializer BytesJsonSerializer MsgPackSerializer A custom serializer can be used anytime with: import httpx_cache with httpx . Client ( cache = httpx_cache . DictCache ( serializer = httpx_cache . DictSerializer ())) as client : response = client . get ( \"https://httpbin.org/get\" ) httpx-cache provides the following serializers: DictSerializer The base serializer used in all other serializers, converts an httpx.Response object into python dict that represents the response. The idea is that using the created dict we should be able to recreate exactly the same response. The serialized dict has the following elements: { \"status_code\" : \"int, required, status code of the response\" , \"headers\" : \"List[Tuple[str, str]], required, list of headers of the original response, can be an empty list\" , \"encoding\" : \"str, optional, encoding of the response if not Null\" , \"_content\" : \"bytes, optional, content of the response if exists (usually if stream is consumed, or response originally has just a basic content), if not found, 'stream_content' should be provided.\" , \"stream_content\" : \"bytes, optional, in case the response contains a stream that is loaded only after the transport finishies his work, will be converted to an httpx.BytesStream when recreating the response.\" } StringJsonSerializer Inherits from DictSerializer , this is the result of json.dumps of the above generated dict. BytesJsonSerializer Inherits from StringJsonSerializer , utf-8 encoded json string. MsgPackSerializer (default) Inherits from DictSerializer , this is the result of msgpack.dumps of the above generated dict.","title":"User Guide"},{"location":"guide/#user-guide","text":"httpx-cache provides: A sync/async httpx compatible caching client and/or transport. Support for an in memeory dict cache and a file cache. Support for different serializers: dict, str, bytes, msgpack","title":"User Guide"},{"location":"guide/#client","text":"httpx recommends usig a client instance of anything more that experimentation, one-off scripts, or prototypes. Caching is one such advanced use cases, that's why httpx-cache provides it's own Custom client that has exactly the same features as the original httpx.Client (inherits from the httpx.Client class), but wraps the default (or custom) transport in an httpx_cache.CacheControlTransport .","title":"Client"},{"location":"guide/#usage-with-default-values","text":"Excluding the caching algorithms, httpx_cache.Client (or AsyncClient ) behaves similary to httpx.Client (or AsyncClient ). For caching, httpx_cache.Client adds 3 new key-args to the table: cache : An optional value for which cache type to use, defaults to an in-memory dict cache if not provided. cacheable_methods : tuple of str http methods that support caching (if a request does not use one of these methods, it's corresponding response will not be cached), defaults to ('GET',) cacheable_status_codes : tuple of int http status codes that supports caching (if response does not have one of these status codes, it will not be cached), defaults to: (200, 203, 300, 301, 308) always_cache : bool, if True, all valid responses will be cached, regardless of the no-store directive set in either the request or response, defaults to False. Note: When using the httpx_cache client or transport, a new property will be added to the response to specify whether it comes from cache or not: response.from_cache: bool Example usage: import httpx_cache with httpx_cache . Client () as client : response1 = client . get ( \"https://httpbin.org/get\" ) # will be cached response2 = client . get ( \"https://httpbin.org/get\" ) # will get it from cache assert response1 . from_cache is False assert response2 . from_cache is True","title":"Usage with Default Values"},{"location":"guide/#asyncclient","text":"Same as httpx.AsyncClient , httpx_cache also provides an httpx_cache.AsyncClient that supports samencaching args as httpx_cache.Client . import httpx_cache async with httpx_cache . AsyncClient () as client : response1 = await client . get ( \"https://httpbin.org/get\" ) # will be cached response2 = await client . get ( \"https://httpbin.org/get\" ) # will get it from cache assert response1 . from_cache is False assert response2 . from_cache is True","title":"AsyncClient"},{"location":"guide/#response-stream","text":"When using a streaming response, the response will not be cached until the stream is fully consumed. The reason being that to cache a response we need it to have a content property and this content is set only when the user has fully consumed the stream. (httpx_cache handles this automatically with a callback, it should have no effect on the user usual routines when using a stream.) import logging import tempfile import rich.progress from rich.logging import RichHandler import httpx_cache logging . basicConfig ( level = \"DEBUG\" , format = \" %(message)s \" , datefmt = \"[ %X ]\" , handlers = [ RichHandler ()] ) logger = logging . getLogger ( \"httpx_cache.example\" ) with tempfile . NamedTemporaryFile () as download_file : url = \"https://speed.hetzner.de/100MB.bin\" with httpx_cache . Client () as client : logger . info ( f \"Running ' { url } ' download for the first time ...\" ) with client . stream ( \"GET\" , url ) as response : total = int ( response . headers [ \"Content-Length\" ]) logger . info ( \"A streaming response is cached only after the stream is consumed.\" ) with rich . progress . Progress ( \"[progress.percentage] {task.percentage:>3.0f} %\" , rich . progress . BarColumn ( bar_width = None ), rich . progress . DownloadColumn (), rich . progress . TransferSpeedColumn (), rich . progress . TimeElapsedColumn (), ) as progress : download_task = progress . add_task ( \"Download\" , total = total ) for chunk in response . iter_bytes (): download_file . write ( chunk ) progress . update ( download_task , completed = response . num_bytes_downloaded ) logger . info ( f \"Running same ' { url } ' download for the second time ...\" ) logger . info ( \"The response is cached so it should take 0 seconds to iter over \" \"the bin again !\" ) with client . stream ( \"GET\" , url ) as response2 : total = int ( response2 . headers [ \"Content-Length\" ]) with rich . progress . Progress ( \"[progress.percentage] {task.percentage:>3.0f} %\" , rich . progress . BarColumn ( bar_width = None ), rich . progress . DownloadColumn (), rich . progress . TransferSpeedColumn (), rich . progress . TimeElapsedColumn (), ) as progress : download_task = progress . add_task ( \"Download\" , total = total ) for chunk in response2 . iter_bytes (): download_file . write ( chunk ) progress . update ( download_task , completed = response2 . num_bytes_downloaded ) (This script is complete, it should run \"as is\")","title":"Response Stream"},{"location":"guide/#transport","text":"If you prefer to use the original httpx Client, httpx-cache also provides a transport that can be used dircetly with it: The custom caching transport is created following the guilelines here . The (Async-)CacheControlTransport also accepts the 3 key-args: cache : An optional value for which cache type to use, defaults to an in-memory dict cache if not provided. cacheable_methods : tuple of str http methods that support caching (if a request does not use one of these methods, it's corresponding response will not be cached), defaults to ('GET',) cacheable_status_codes : tuple of int http status codes that supports caching (if response does not have one of these status codes, it will not be cached), defaults to: (200, 203, 300, 301, 308) Note: When using the httpx_cache client or transport, a new property will be added to the response to specify whether it comes from cache or not: response.from_cache: bool import httpx import httpx_cache with httpx . Client ( transport = httpx_cache . CacheControlTransport ()) as client : response = client . get ( \"https://httpbin.org/get\" ) # async with httpx.AsyncClient(transport=httpx_cache.AsyncCacheControlTransport()) as client: # response = await client.get(\"https://httpbin.org/get\")","title":"Transport"},{"location":"guide/#cache-types","text":"","title":"Cache Types"},{"location":"guide/#dictcache-default","text":"In-memory dict cache: import httpx import httpx_cache with httpx_cache . Client ( cache = httpx_cache . DictCache ()) as client : response = client . get ( \"https://httpbin.org/get\" )","title":"DictCache (default)"},{"location":"guide/#filecache","text":"import httpx_cache with httpx_cache . Client ( cache = httpx_cache . FileCache ()) as client : response = client . get ( \"https://httpbin.org/get\" ) By default the cached files will be saved in $HOME/.cache/httpx-cache folder. It can be customized using the argument: cache_dir : import httpx_cache with httpx_cache . Client ( cache = httpx_cache . FileCache ( cache_dir = \"./my-custom-dir\" )) as client : response = client . get ( \"https://httpbin.org/get\" )","title":"FileCache"},{"location":"guide/#fsspecuniversal_pathlib-integration","text":"Filecache also works out of the box with fsspec/universal_pathlib so that you can use any filesystem supported by fsspec as a cachedir. Please check the fsspec/universal_pathlib docs for the list of supported filesystems (and schemes) Example with an s3 filesystem: (don't forget to also install the s3fs package to use this backend: pip install universal_pathlib s3fs ) import httpx_cache from upath import UPath cache_dir = UPath ( \"s3://my-bucket/httpx-cache\" ) cache = httpx_cache . FileCache ( cache_dir = cache_dir ) with httpx_cache . Client ( cache = cache ) as client : response = client . get ( \"https://httpbin.org/get\" ) # OR async client # async with httpx_cache.AsyncClient(cache=cache) as client: # response = await client.get(\"https://httpbin.org/get\") # should contain one file, with the cached response print ([ f for f in cache_dir . iterdir ()])","title":"fsspec/universal_pathlib integration"},{"location":"guide/#rediscache","text":"You need to install redis package to use this cache type, or install httpx-cache[redis] to install it automatically. import httpx_cache from httpx_cache.cache.redis import RedisCache with httpx_cache . Client ( cache = RedisCache ( redis_url = \"redis://localhost:6379/0\" )) as client : response = client . get ( \"https://httpbin.org/get\" ) By default all cached responses are saved under the namespace htppx_cache . Optionally a TTL can be provided so that the cached responses expire after the given time (as a python timedelta). It can also accepts direct instances of redis.Redis or redis.StrictRedis clients. import httpx_cache from redis import Redis from httpx_cache.cache.redis import RedisCache redis_client = Redis ( host = \"localhost\" , port = 6379 , db = 0 ) cache = RedisCache ( redis = redis_client , namespace = \"my-custom-namespace\" , default_ttl = timedelta ( hours = 1 )) with httpx_cache . Client ( cache = cache ) as client : response = client . get ( \"https://httpbin.org/get\" )","title":"RedisCache"},{"location":"guide/#serializer-types","text":"Before caching an httpx.Response it needs to be serialized to a cacheable format supported by the used cache type (Dict/File). Serializer DictCache FileCache RedisCache DictSerializer StringJsonSerializer BytesJsonSerializer MsgPackSerializer A custom serializer can be used anytime with: import httpx_cache with httpx . Client ( cache = httpx_cache . DictCache ( serializer = httpx_cache . DictSerializer ())) as client : response = client . get ( \"https://httpbin.org/get\" ) httpx-cache provides the following serializers:","title":"Serializer Types"},{"location":"guide/#dictserializer","text":"The base serializer used in all other serializers, converts an httpx.Response object into python dict that represents the response. The idea is that using the created dict we should be able to recreate exactly the same response. The serialized dict has the following elements: { \"status_code\" : \"int, required, status code of the response\" , \"headers\" : \"List[Tuple[str, str]], required, list of headers of the original response, can be an empty list\" , \"encoding\" : \"str, optional, encoding of the response if not Null\" , \"_content\" : \"bytes, optional, content of the response if exists (usually if stream is consumed, or response originally has just a basic content), if not found, 'stream_content' should be provided.\" , \"stream_content\" : \"bytes, optional, in case the response contains a stream that is loaded only after the transport finishies his work, will be converted to an httpx.BytesStream when recreating the response.\" }","title":"DictSerializer"},{"location":"guide/#stringjsonserializer","text":"Inherits from DictSerializer , this is the result of json.dumps of the above generated dict.","title":"StringJsonSerializer"},{"location":"guide/#bytesjsonserializer","text":"Inherits from StringJsonSerializer , utf-8 encoded json string.","title":"BytesJsonSerializer"},{"location":"guide/#msgpackserializer-default","text":"Inherits from DictSerializer , this is the result of msgpack.dumps of the above generated dict.","title":"MsgPackSerializer (default)"}]}